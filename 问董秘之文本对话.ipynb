{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecac1a38-6d97-48d0-8592-ebe6b52fafe7",
   "metadata": {},
   "source": [
    "# 加载环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb37d99-225d-4a4a-94bf-ea204a7de878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Optional\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "# 首先导入所需第三方库\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# 加载嵌入模型\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "# 建立索引\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a8a0e-fce3-4fc8-aa88-fbe44c79c152",
   "metadata": {},
   "source": [
    "# 配置LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c71ffda-a7c2-4b4e-8713-6ddf4db2842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"Update to your API key\"  # Update to your API key\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1cbb64-cc1b-4d4a-95e7-7e655f8c0e91",
   "metadata": {},
   "source": [
    "# 自定义大模型 Internlm-chat-7b-finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2312290-37ee-4875-b7ef-059271eb1d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从本地加载模型...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7bd70a7b9647eeb362688d2a2afb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成本地模型的加载\n"
     ]
    }
   ],
   "source": [
    "class InternLM_LLM(LLM):\n",
    "    # 基于本地 InternLM 自定义 LLM 类\n",
    "    tokenizer : AutoTokenizer = None\n",
    "    model: AutoModelForCausalLM = None\n",
    "\n",
    "    def __init__(self, model_path :str):\n",
    "        # model_path: InternLM 模型路径\n",
    "        # 从本地初始化模型\n",
    "        super().__init__()\n",
    "        print(\"正在从本地加载模型...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True).to(torch.bfloat16).cuda()\n",
    "        self.model = self.model.eval()\n",
    "        print(\"完成本地模型的加载\")\n",
    "\n",
    "    def _call(self, prompt : str, stop: Optional[List[str]] = None,\n",
    "                run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "                **kwargs: Any):\n",
    "        # 重写调用函数\n",
    "        system_prompt = \"\"\"You are an AI assistant whose name is InternLM (书生·浦语).\n",
    "        - InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.\n",
    "        - InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [(system_prompt, '')]\n",
    "        response, history = self.model.chat(self.tokenizer, prompt , history=messages)\n",
    "        return response\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"InternLM2\"\n",
    "\n",
    "# 加载大模型\n",
    "#llm = InternLM_LLM(\"/root/share/model_repos/internlm2-chat-7b\")\n",
    "llm = InternLM_LLM(\"/root/project/bisai2/sft-guanfang-self/merged_7b_e10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f795e-5274-47b7-81cc-c8b0a9000255",
   "metadata": {},
   "source": [
    "## 创建检索库(如果有)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fff405e-b2aa-4e92-bcc4-9f406598ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /root/model/jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 加载已有数据库\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"/root/model/jinaai/jina-embeddings-v2-base-zh\")\n",
    "vectordb = FAISS.load_local('./vectordb', embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335068a-17f2-4462-94d3-f7a8a4c40c78",
   "metadata": {},
   "source": [
    "## 文本对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bfbbdcb-50de-4e69-bf15-4e4ca8b82641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "截至今年上半年，上汽跃进有5800台左右的车辆搭载德威系列发动机。 \n"
     ]
    }
   ],
   "source": [
    "# 建立一个链，该链接受问题和检索到的文档并生成答案\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"使用以上下文来回答用户的问题。总是使用中文回答。\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "如果给定的上下文无法让你做出回答，请对回答的内容以“*”开头，然后根据你的理解作答。\n",
    "有用的回答: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "\n",
    "#对于给定的问题，我们可以使用检索器动态选择最相关的文档并将其传递进去\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# 返回结果\n",
    "response = retrieval_chain.invoke({\"input\": \"上汽集团有多少车辆搭载了德威系列的发动机\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internlm-demo",
   "language": "python",
   "name": "internlm-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
